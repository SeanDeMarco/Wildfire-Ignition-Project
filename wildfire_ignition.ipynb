{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6059da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89945628",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d493a",
   "metadata": {},
   "source": [
    "# Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3298c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_path = \"dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016d769e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>distance_fire_stations</th>\n",
       "      <th>distance_rivers</th>\n",
       "      <th>distance_roads</th>\n",
       "      <th>distance_powerlines</th>\n",
       "      <th>cropland</th>\n",
       "      <th>forest_deciduous_broad</th>\n",
       "      <th>forest_deciduous_needle</th>\n",
       "      <th>forest_evergreen_broad</th>\n",
       "      <th>forest_evergreen_needle</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_wind_angle</th>\n",
       "      <th>avg_rel_hum</th>\n",
       "      <th>avg_soil</th>\n",
       "      <th>sum_prec</th>\n",
       "      <th>forest</th>\n",
       "      <th>vegetation_class</th>\n",
       "      <th>Year</th>\n",
       "      <th>max_max_temp</th>\n",
       "      <th>yearly_avg_temp</th>\n",
       "      <th>ignition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-19</td>\n",
       "      <td>13287.682266</td>\n",
       "      <td>7211.102551</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>30196.233209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>225.773605</td>\n",
       "      <td>56.837185</td>\n",
       "      <td>0.297854</td>\n",
       "      <td>0.360376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>forest</td>\n",
       "      <td>2015</td>\n",
       "      <td>62.552337</td>\n",
       "      <td>14.994683</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-02-17</td>\n",
       "      <td>8721.381771</td>\n",
       "      <td>2358.495283</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>13768.169813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>209.708847</td>\n",
       "      <td>61.120739</td>\n",
       "      <td>0.264534</td>\n",
       "      <td>0.020176</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>forest</td>\n",
       "      <td>2003</td>\n",
       "      <td>60.787457</td>\n",
       "      <td>15.053698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-02-26</td>\n",
       "      <td>10796.411441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015.564437</td>\n",
       "      <td>6254.998002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.341278</td>\n",
       "      <td>63.017559</td>\n",
       "      <td>0.208871</td>\n",
       "      <td>0.025395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>forest</td>\n",
       "      <td>2012</td>\n",
       "      <td>63.420256</td>\n",
       "      <td>15.001883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-11-10</td>\n",
       "      <td>8253.787010</td>\n",
       "      <td>559.016994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37350.535471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.557823</td>\n",
       "      <td>64.673866</td>\n",
       "      <td>0.156506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>wetland</td>\n",
       "      <td>2004</td>\n",
       "      <td>60.394119</td>\n",
       "      <td>14.850611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-03-19</td>\n",
       "      <td>9905.806378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1903.943276</td>\n",
       "      <td>6427.480066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>316.951508</td>\n",
       "      <td>56.103680</td>\n",
       "      <td>0.208831</td>\n",
       "      <td>0.119717</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>forest</td>\n",
       "      <td>2003</td>\n",
       "      <td>69.570496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  distance_fire_stations  distance_rivers  distance_roads  \\\n",
       "0  2015-11-19            13287.682266      7211.102551     1250.000000   \n",
       "1  2003-02-17             8721.381771      2358.495283      250.000000   \n",
       "2  2012-02-26            10796.411441         0.000000     2015.564437   \n",
       "3  2004-11-10             8253.787010       559.016994        0.000000   \n",
       "4  2003-03-19             9905.806378         0.000000     1903.943276   \n",
       "\n",
       "   distance_powerlines  cropland  forest_deciduous_broad  \\\n",
       "0         30196.233209       0.0                     0.0   \n",
       "1         13768.169813       0.0                     0.0   \n",
       "2          6254.998002       0.0                     0.0   \n",
       "3         37350.535471       0.0                     0.0   \n",
       "4          6427.480066       0.0                     0.0   \n",
       "\n",
       "   forest_deciduous_needle  forest_evergreen_broad  forest_evergreen_needle  \\\n",
       "0                      0.0                1.000000                      0.0   \n",
       "1                      0.0                0.416667                      0.0   \n",
       "2                      0.0                0.666667                      0.0   \n",
       "3                      0.0                0.000000                      0.0   \n",
       "4                      0.0                0.750000                      0.0   \n",
       "\n",
       "   ...  avg_wind_angle  avg_rel_hum  avg_soil  sum_prec    forest  \\\n",
       "0  ...      225.773605    56.837185  0.297854  0.360376  1.000000   \n",
       "1  ...      209.708847    61.120739  0.264534  0.020176  0.833333   \n",
       "2  ...       76.341278    63.017559  0.208871  0.025395  1.000000   \n",
       "3  ...       68.557823    64.673866  0.156506  0.000000  0.000000   \n",
       "4  ...      316.951508    56.103680  0.208831  0.119717  0.916667   \n",
       "\n",
       "   vegetation_class  Year  max_max_temp  yearly_avg_temp  ignition  \n",
       "0            forest  2015     62.552337        14.994683         1  \n",
       "1            forest  2003     60.787457        15.053698         1  \n",
       "2            forest  2012     63.420256        15.001883         1  \n",
       "3           wetland  2004     60.394119        14.850611         1  \n",
       "4            forest  2003     69.570496              NaN         1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataframe_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924476b3",
   "metadata": {},
   "source": [
    "# Structure of the dataframe and Task\n",
    "\n",
    "\n",
    "- Each row consists of an ignition or non-ignition point with the given features associated. The features were chosen as potentially influencing ignition.\n",
    "\n",
    "\n",
    "- The last column named `ignition` says if the point was a real ignition point (meaning that it occurred historically), in that case the value is `1`. Otherwise, when the value is `0`, it means that it is a 'non-ignition point'.\n",
    "\n",
    "\n",
    "- The columns `cropland` to `wetland` gives the ratio of each of the vegetation classes under which the ignition or non-ignition point lies. The sum of these ratios should be equal to 1. For more information refer to this website: https://lcviewer.vito.be/\n",
    "\n",
    "\n",
    "- The temperatures should be in degrees celsius `(°C)`.\n",
    "\n",
    "\n",
    "- The weather data come from different sources and they might have different units.\n",
    "\n",
    "| Column name | Definition | Unit |\n",
    "|--------|-----------|--------|\n",
    "| `ignition`   | Target column| Boolean: {1,0} |\n",
    "| `distance_{feature}` | Distance to nearest feature  |  Meters (m) |\n",
    "| vegetation class: from `cropland` to `wetland`  |  Ratio of each of the vegetation classes  under which the ignition or non-ignition point lies    |  No unit (between 0 and 1)  |\n",
    "| `aspect`  |  Orientation of the slope    |  Degrees (°)  |\n",
    "| `elevation`  |  elevation value    |  Meters  |\n",
    "| `slope`  |  Slope value    |  Degrees (°)  |\n",
    "| `pop_dens`  |  Population density value    |  Persons per km2  |\n",
    "| `max_temp`  |  Maximum temperature of the day    |  Degrees celsius (°C)  |\n",
    "| `avg_temp`  |  Average temperature of the day   |  Degrees celsius (°C)  |\n",
    "| `max_wind_vel`  |  Maximum wind velocity of the day    |  Meters per second (m/s)  |\n",
    "| `avg_wind_angle`  |  Average angle of the vector wind over the day    |  Degrees (°)  |\n",
    "| `avg_rel_hum`  |  Average relative humidity over the day    |  %  |\n",
    "| `avg_soil`  |  Average soil moisture of the day    |  m3/m3  |\n",
    "| `sum_prec`  |  Cumulative rainfall precipitation of the day    |  Millimeters (mm)  |\n",
    "| `yearly_avg_temp`  |  Average temperature over the year    |  Degrees celsius (°C)  |\n",
    "| `anom_{feature}`  |  Standardized anomaly of weather for the given day over the last 30 years. When the anomaly is positive, it means that the feature value is greater that the 30-year average    |  No unity |\n",
    "| `forest`  |  Sum of all the columns where the names start with `forest`   |  No unit  |\n",
    "| `vegetation_class`  |  Vegetation with the max occurrence in the vicinity of the ignition/non-ignition point    |  Without unit  |\n",
    "| `Year`  |  Year of ignition    |  Without unit  |\n",
    "| `max_max_temp`  |  Missing information    |  Missing information  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a321157-084a-4a20-9865-7c7aec4be2af",
   "metadata": {},
   "source": [
    "# Main steps of a data science project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9679306f-4869-4b72-b97a-72ec28235bde",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph TD\n",
    "    A[Start] --> B[Identify Project Objectives]\n",
    "    B --> C[Identify Required Data]\n",
    "    C --> D[Load the Data]\n",
    "    D --> E[Explore and Understand Data]\n",
    "    E --> F[Preprocess the Data]\n",
    "    F --> G[Feature Selection]\n",
    "    G --> H[Split Data into Training and Test Sets]\n",
    "    H --> I[Select and Train Algorithm]\n",
    "    I --> J[Evaluate the Model]\n",
    "    J --> K{Model Performance Acceptable?}\n",
    "    K -- Yes --> L[Deploy / Communicate Results]\n",
    "    K -- No --> F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9db7a2-0111-49fe-a3b5-8f64261b732b",
   "metadata": {},
   "source": [
    "Before starting any data science project, it essential to clearly define the objectives of the project. The project objectives guide all subsequent steps, including what algorithms and what data is to be used.\n",
    "\n",
    "Once the objectives have been established, the next step is to source the data that is required to carry out the project objectives.\n",
    "\n",
    "With the data in-hand, the focus of the project shifts to understand the data. This phase of the project deals with uncovers data patterns and potential issues. Following exploring the data, the data must be cleaned and processed. The preprocessing of the data is one of the most important steps in any data science project and often determining the overall success of the project. Data processing can be considered a \"make or break\" for any project.\n",
    "\n",
    "Once the data is preprocessed, the features and labels must be selected and the dataset split into training and test sets.\n",
    "\n",
    "Next, select an appropriate algorithm based on the project objectives. It is typically considered good practice to select multiple algorithms and evaluate their performance. Note that each algorithm must suit the task at hand and must be adapated as needed. For example, the of use logistic regression for classification tasks over linear regression.\n",
    "\n",
    "With the data prepared and algorithms selected, the models are then trained and evaluated. If the performance is acceptable, the results should be presented and the model may proceed to deployment. However, if the model performance is unsatisfactory, one must go back to preprocessing and feature selection to investigate why the model underperformed. The goal of this step should be to identify whether the poor performance stems from insufficient data cleaning, suboptimal features or a bad model choice. Iterate through these steps until the model meets the project's success criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf9c11-6c65-4bf0-94b0-b6e08ecc4737",
   "metadata": {},
   "source": [
    "# Carrying Out the Classification Project\n",
    "\n",
    "## Problem Definition and Objective Identification\n",
    "\n",
    "The goal of this project is to create a classification algorithm based on a number of features from a given dataset, the classifier will be able to predict whether a given set of features correspond to an ignition or not. \n",
    "\n",
    "The dataset is a multidimensional space having 42 columns, one of which is the target label, ignition. Ignition is either 1 or 0. Meaning that this task is a **binary classification task**.\n",
    "\n",
    "The next step is to understand the data and try find correlations in the data. It is expected that in such a large dataset, not all features are going to have strong correlations and therefore, may be considered for removal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d79549-5931-460e-967f-4474df8cc9bc",
   "metadata": {},
   "source": [
    "## Understanding and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eda3a33-f24b-4bd4-9e5b-ddfe7ef3663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22035 entries, 0 to 22034\n",
      "Data columns (total 42 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Date                     22035 non-null  object \n",
      " 1   distance_fire_stations   22030 non-null  float64\n",
      " 2   distance_rivers          22030 non-null  float64\n",
      " 3   distance_roads           22030 non-null  float64\n",
      " 4   distance_powerlines      22030 non-null  float64\n",
      " 5   cropland                 22030 non-null  float64\n",
      " 6   forest_deciduous_broad   22030 non-null  float64\n",
      " 7   forest_deciduous_needle  22030 non-null  float64\n",
      " 8   forest_evergreen_broad   22030 non-null  float64\n",
      " 9   forest_evergreen_needle  22030 non-null  float64\n",
      " 10  forest_mixed             22030 non-null  float64\n",
      " 11  forest_unknown           22030 non-null  float64\n",
      " 12  herbaceous_vegetation    22030 non-null  float64\n",
      " 13  moss_lichen              22030 non-null  float64\n",
      " 14  shrubland                22030 non-null  float64\n",
      " 15  sprarse_vegetation       22030 non-null  float64\n",
      " 16  urban                    22030 non-null  float64\n",
      " 17  water                    22030 non-null  float64\n",
      " 18  wetland                  22030 non-null  float64\n",
      " 19  aspect                   22035 non-null  float64\n",
      " 20  elevation                22035 non-null  float64\n",
      " 21  pop_dens                 22035 non-null  float64\n",
      " 22  slope                    22035 non-null  float64\n",
      " 23  anom_max_temp            22035 non-null  float64\n",
      " 24  anom_max_wind_vel        22035 non-null  float64\n",
      " 25  anom_avg_temp            22035 non-null  float64\n",
      " 26  anom_avg_rel_hum         22035 non-null  float64\n",
      " 27  anom_avg_soil            22035 non-null  float64\n",
      " 28  anom_sum_prec            22035 non-null  float64\n",
      " 29  max_temp                 22035 non-null  float64\n",
      " 30  max_wind_vel             22035 non-null  float64\n",
      " 31  avg_temp                 22035 non-null  float64\n",
      " 32  avg_wind_angle           22035 non-null  float64\n",
      " 33  avg_rel_hum              22035 non-null  float64\n",
      " 34  avg_soil                 22035 non-null  float64\n",
      " 35  sum_prec                 22035 non-null  float64\n",
      " 36  forest                   22035 non-null  float64\n",
      " 37  vegetation_class         22003 non-null  object \n",
      " 38  Year                     22035 non-null  int64  \n",
      " 39  max_max_temp             22035 non-null  float64\n",
      " 40  yearly_avg_temp          15204 non-null  float64\n",
      " 41  ignition                 22035 non-null  int64  \n",
      "dtypes: float64(38), int64(2), object(2)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Getting the information on the dataset such as datatypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e8ac3ba-a723-40a9-9299-427985bdc6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_fire_stations</th>\n",
       "      <th>distance_rivers</th>\n",
       "      <th>distance_roads</th>\n",
       "      <th>distance_powerlines</th>\n",
       "      <th>cropland</th>\n",
       "      <th>forest_deciduous_broad</th>\n",
       "      <th>forest_deciduous_needle</th>\n",
       "      <th>forest_evergreen_broad</th>\n",
       "      <th>forest_evergreen_needle</th>\n",
       "      <th>forest_mixed</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>avg_wind_angle</th>\n",
       "      <th>avg_rel_hum</th>\n",
       "      <th>avg_soil</th>\n",
       "      <th>sum_prec</th>\n",
       "      <th>forest</th>\n",
       "      <th>Year</th>\n",
       "      <th>max_max_temp</th>\n",
       "      <th>yearly_avg_temp</th>\n",
       "      <th>ignition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22030.000000</td>\n",
       "      <td>22030.000000</td>\n",
       "      <td>22030.000000</td>\n",
       "      <td>22030.000000</td>\n",
       "      <td>22030.000000</td>\n",
       "      <td>22030.000000</td>\n",
       "      <td>22030.0</td>\n",
       "      <td>22030.000000</td>\n",
       "      <td>22030.000000</td>\n",
       "      <td>22030.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>15204.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23646.387792</td>\n",
       "      <td>5966.777537</td>\n",
       "      <td>5152.597702</td>\n",
       "      <td>30127.951951</td>\n",
       "      <td>0.006415</td>\n",
       "      <td>0.013557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326108</td>\n",
       "      <td>-4584.657286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>158.859675</td>\n",
       "      <td>197.707583</td>\n",
       "      <td>76.109929</td>\n",
       "      <td>0.285717</td>\n",
       "      <td>1.662872</td>\n",
       "      <td>0.426235</td>\n",
       "      <td>2011.278784</td>\n",
       "      <td>59.230929</td>\n",
       "      <td>14.999755</td>\n",
       "      <td>0.150669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19248.657525</td>\n",
       "      <td>7515.660146</td>\n",
       "      <td>6924.754655</td>\n",
       "      <td>30099.446768</td>\n",
       "      <td>0.057848</td>\n",
       "      <td>0.088239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433120</td>\n",
       "      <td>20915.699938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>135.801507</td>\n",
       "      <td>83.336828</td>\n",
       "      <td>8.027890</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>3.230198</td>\n",
       "      <td>0.455856</td>\n",
       "      <td>5.693506</td>\n",
       "      <td>7.983432</td>\n",
       "      <td>0.100675</td>\n",
       "      <td>0.357734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.109107</td>\n",
       "      <td>0.792745</td>\n",
       "      <td>40.705662</td>\n",
       "      <td>0.050758</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>34.109174</td>\n",
       "      <td>14.597322</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9568.829605</td>\n",
       "      <td>707.106781</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>8265.137627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.687609</td>\n",
       "      <td>133.581253</td>\n",
       "      <td>70.623573</td>\n",
       "      <td>0.233063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>53.440945</td>\n",
       "      <td>14.931427</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18494.931738</td>\n",
       "      <td>2610.076627</td>\n",
       "      <td>1581.138830</td>\n",
       "      <td>20846.161854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>276.348625</td>\n",
       "      <td>203.072937</td>\n",
       "      <td>76.005028</td>\n",
       "      <td>0.287844</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>58.614709</td>\n",
       "      <td>14.999861</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32310.988843</td>\n",
       "      <td>8384.323013</td>\n",
       "      <td>7941.190087</td>\n",
       "      <td>41340.053217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>280.721741</td>\n",
       "      <td>257.033798</td>\n",
       "      <td>81.626057</td>\n",
       "      <td>0.346534</td>\n",
       "      <td>1.854040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>64.858667</td>\n",
       "      <td>15.068628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>110474.261708</td>\n",
       "      <td>43784.986011</td>\n",
       "      <td>40094.419811</td>\n",
       "      <td>159274.919557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>292.551632</td>\n",
       "      <td>358.530182</td>\n",
       "      <td>98.558968</td>\n",
       "      <td>0.501387</td>\n",
       "      <td>40.440075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>90.376239</td>\n",
       "      <td>15.369208</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       distance_fire_stations  distance_rivers  distance_roads  \\\n",
       "count            22030.000000     22030.000000    22030.000000   \n",
       "mean             23646.387792      5966.777537     5152.597702   \n",
       "std              19248.657525      7515.660146     6924.754655   \n",
       "min                  0.000000         0.000000        0.000000   \n",
       "25%               9568.829605       707.106781      250.000000   \n",
       "50%              18494.931738      2610.076627     1581.138830   \n",
       "75%              32310.988843      8384.323013     7941.190087   \n",
       "max             110474.261708     43784.986011    40094.419811   \n",
       "\n",
       "       distance_powerlines      cropland  forest_deciduous_broad  \\\n",
       "count         22030.000000  22030.000000            22030.000000   \n",
       "mean          30127.951951      0.006415                0.013557   \n",
       "std           30099.446768      0.057848                0.088239   \n",
       "min               0.000000      0.000000                0.000000   \n",
       "25%            8265.137627      0.000000                0.000000   \n",
       "50%           20846.161854      0.000000                0.000000   \n",
       "75%           41340.053217      0.000000                0.000000   \n",
       "max          159274.919557      1.000000                1.000000   \n",
       "\n",
       "       forest_deciduous_needle  forest_evergreen_broad  \\\n",
       "count                  22030.0            22030.000000   \n",
       "mean                       0.0                0.326108   \n",
       "std                        0.0                0.433120   \n",
       "min                        0.0                0.000000   \n",
       "25%                        0.0                0.000000   \n",
       "50%                        0.0                0.000000   \n",
       "75%                        0.0                0.916667   \n",
       "max                        0.0                1.000000   \n",
       "\n",
       "       forest_evergreen_needle  forest_mixed  ...      avg_temp  \\\n",
       "count             22030.000000       22030.0  ...  22035.000000   \n",
       "mean              -4584.657286           0.0  ...    158.859675   \n",
       "std               20915.699938           0.0  ...    135.801507   \n",
       "min             -100000.000000           0.0  ...     -4.109107   \n",
       "25%                   0.000000           0.0  ...      7.687609   \n",
       "50%                   0.000000           0.0  ...    276.348625   \n",
       "75%                   0.000000           0.0  ...    280.721741   \n",
       "max                   0.000000           0.0  ...    292.551632   \n",
       "\n",
       "       avg_wind_angle   avg_rel_hum      avg_soil      sum_prec        forest  \\\n",
       "count    22035.000000  22035.000000  22035.000000  22035.000000  22035.000000   \n",
       "mean       197.707583     76.109929      0.285717      1.662872      0.426235   \n",
       "std         83.336828      8.027890      0.078390      3.230198      0.455856   \n",
       "min          0.792745     40.705662      0.050758     -0.000007      0.000000   \n",
       "25%        133.581253     70.623573      0.233063      0.000000      0.000000   \n",
       "50%        203.072937     76.005028      0.287844      0.154361      0.166667   \n",
       "75%        257.033798     81.626057      0.346534      1.854040      1.000000   \n",
       "max        358.530182     98.558968      0.501387     40.440075      1.000000   \n",
       "\n",
       "               Year  max_max_temp  yearly_avg_temp      ignition  \n",
       "count  22035.000000  22035.000000     15204.000000  22035.000000  \n",
       "mean    2011.278784     59.230929        14.999755      0.150669  \n",
       "std        5.693506      7.983432         0.100675      0.357734  \n",
       "min     2001.000000     34.109174        14.597322      0.000000  \n",
       "25%     2006.000000     53.440945        14.931427      0.000000  \n",
       "50%     2012.000000     58.614709        14.999861      0.000000  \n",
       "75%     2016.000000     64.858667        15.068628      0.000000  \n",
       "max     2021.000000     90.376239        15.369208      1.000000  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describing the dataset to see the style of data that is being dealt with\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52413c09-1ef8-4f41-94c7-86a6666e9ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "220adbc5-04fb-41ac-82ff-fe7613414a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg_rel_hum               -0.269664\n",
       "distance_roads            -0.268259\n",
       "water                     -0.254303\n",
       "distance_fire_stations    -0.228656\n",
       "distance_rivers           -0.218113\n",
       "distance_powerlines       -0.205647\n",
       "anom_avg_soil             -0.192976\n",
       "anom_avg_rel_hum          -0.156313\n",
       "avg_soil                  -0.136861\n",
       "max_wind_vel              -0.110371\n",
       "anom_sum_prec             -0.108719\n",
       "sum_prec                  -0.089841\n",
       "cropland                  -0.022591\n",
       "sprarse_vegetation        -0.006609\n",
       "aspect                    -0.004460\n",
       "Year                       0.007185\n",
       "yearly_avg_temp            0.012401\n",
       "forest_evergreen_needle    0.012867\n",
       "avg_temp                   0.016031\n",
       "shrubland                  0.026196\n",
       "anom_max_wind_vel          0.028030\n",
       "anom_avg_temp              0.040474\n",
       "avg_wind_angle             0.052949\n",
       "elevation                  0.052994\n",
       "herbaceous_vegetation      0.061074\n",
       "wetland                    0.076226\n",
       "forest_evergreen_broad     0.091934\n",
       "forest_deciduous_broad     0.097047\n",
       "urban                      0.100623\n",
       "slope                      0.151058\n",
       "anom_max_temp              0.159961\n",
       "pop_dens                   0.164220\n",
       "forest                     0.196014\n",
       "forest_unknown             0.214991\n",
       "max_temp                   0.295029\n",
       "max_max_temp               0.295029\n",
       "ignition                   1.000000\n",
       "forest_deciduous_needle         NaN\n",
       "forest_mixed                    NaN\n",
       "moss_lichen                     NaN\n",
       "Name: ignition, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the data with datatypes flaot64 and int64 to see if there are linear correlations with ignition\n",
    "df_correlation = df.select_dtypes(include=['float64', 'int64'])\n",
    "df_correlation.corr()['ignition'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedca54c-3b9f-44df-97e0-df2237494d16",
   "metadata": {},
   "source": [
    "Since the goal of this task is to classify whether certain data corresponds to an ignition point, the correlation between data and ignition was checked. It was noted that forest_deciduous_needle, forest_mixed and moss_lichen had no correlation with ignition, indicating that these most likely had no variation in data. Therefore, these 3 datafields are not important and can therefore be dropped.\n",
    "\n",
    "Looking at the information on the dataset, yearly_avg_temp was observed to have approximately 6800 NaN datapoints. Yearly average temperature could influence whether a point is classified as an ignition point however, the data needs to be looked into further before dropping this data. The options for this column are to either impute the data should it be valuable or drop the column entirely.\n",
    "\n",
    "Moreover, there appears to be overlapping data such as Date and Year, naturally the Year column can be dropped and Date used. It may be worth converting Date into Month, Year and Day of the year as wildfires could be seasonal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6975a94-b913-415d-a9f6-1ee975873472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NaN correlated rows\n",
    "df.drop(columns=['forest_deciduous_needle', 'forest_mixed', 'moss_lichen'], inplace=True)\n",
    "\n",
    "# Handling Date and converting to standalone columns\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['DayofYear'] = df['Date'].dt.dayofyear\n",
    "df.drop(columns=['Year'], inplace=True)\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff0af7-691b-4393-9f23-e125d87d7975",
   "metadata": {},
   "source": [
    "Since yearly_avg_temp is a yearly average, the data can be grouped by year and using the valid data, the NaN values can be converted to the mean of that year. This preserves possibly impactful data rather than just removing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc8d4723-aa4e-47b5-bb25-2d79f9877488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining NaNs in yearly_avg_temp : 0\n"
     ]
    }
   ],
   "source": [
    "# Imputing yearly_avg_temp by filling the NaN values with the mean yearly_avg_temp of that year from the valid data\n",
    "df['yearly_avg_temp'] = df.groupby('Year')['yearly_avg_temp'].transform(lambda x: x.fillna(x.mean()))\n",
    "print(\"Remaining NaNs in yearly_avg_temp :\", df['yearly_avg_temp'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a0d25a-ed08-496a-b210-b2facadd10d6",
   "metadata": {},
   "source": [
    "From the information on the dataset, it was noted that columns from cropland to wetland gives the ratio of vegetation class. Moreover, the sum of these ratios must be 1. Therefore, this must be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e28243-f321-4eca-b72e-3856abc219d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forest_evergreen_needle    1010\n",
       "forest_deciduous_broad        0\n",
       "cropland                      0\n",
       "forest_evergreen_broad        0\n",
       "forest_unknown                0\n",
       "herbaceous_vegetation         0\n",
       "shrubland                     0\n",
       "sprarse_vegetation            0\n",
       "urban                         0\n",
       "water                         0\n",
       "wetland                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing the vegetation columns\n",
    "veg_columns = [\n",
    "    'cropland',\n",
    "    'forest_deciduous_broad',\n",
    "    'forest_evergreen_broad',\n",
    "    'forest_evergreen_needle',\n",
    "    'forest_unknown',\n",
    "    'herbaceous_vegetation',\n",
    "    'shrubland',\n",
    "    'sprarse_vegetation',\n",
    "    'urban',\n",
    "    'water',\n",
    "    'wetland'\n",
    "]\n",
    "\n",
    "# Summing the ratios if the vegetation class\n",
    "row_sums = df[veg_columns].sum(axis=1)\n",
    "# Creating a mask that returns True if the sum is not correct. Note that the condition is not == 1 as to account for computational precision\n",
    "invalid_sum_mask = ~row_sums.between(0.999, 1.001)\n",
    "\n",
    "# Checking what classes are contributing to the bad summation by collecting the values that are outside the range [0,1]\n",
    "invalid_values = (df[veg_columns] < 0) | (df[veg_columns] > 1)\n",
    "invalid_by_class = invalid_values.sum().sort_values(ascending=False)\n",
    "invalid_by_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5a1db-a4ed-47c3-9c3f-7882d1394fd3",
   "metadata": {},
   "source": [
    "Only entries from forest_evergreen_needle are outside the range, let us inspect what the bad data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "753b08e8-6b8c-4c85-bbac-6490087a5e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forest_evergreen_needle\n",
       "-100000.0    1010\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the invalid datapoints from forest_evergreen_needle\n",
    "invalid_forest_evergreen_needle = df.loc[\n",
    "    (df['forest_evergreen_needle'] < 0) | (df['forest_evergreen_needle'] > 1),\n",
    "    'forest_evergreen_needle'\n",
    "]\n",
    "\n",
    "# Seeing what the erraneous values are\n",
    "invalid_value_counts = invalid_forest_evergreen_needle.value_counts()\n",
    "invalid_value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e03bee-d0a7-4488-bdb2-f6889bd1bd8c",
   "metadata": {},
   "source": [
    "The erraneous values are all identical and an extreme value. The first check is to set the extreme value to 0, if the sum is good after setting the extreme values to 0 then the error can be considered fixed. If not, these rows should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f84fb371-8d8b-4a43-8b22-e696613f7d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of remaning invalid rows are: 5\n"
     ]
    }
   ],
   "source": [
    "# Creating a mask that returns true if the value is outside the range [0,1]\n",
    "invalid_mask = (df['forest_evergreen_needle'] < 0) | (df['forest_evergreen_needle'] > 1)\n",
    "\n",
    "# Setting the extreme values to zero\n",
    "df.loc[invalid_mask, 'forest_evergreen_needle'] = 0\n",
    "# Recalculating the sum and checking if the == 1 condition is true\n",
    "row_sums = df[veg_columns].sum(axis=1)\n",
    "invalid_sum_mask = ~row_sums.between(0.999, 1.001)\n",
    "num_invalid_rows = invalid_sum_mask.sum()\n",
    "print('The number of remaning invalid rows are:', num_invalid_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22bc314-841b-455b-8955-27c467eb3910",
   "metadata": {},
   "source": [
    "From the above it can be seen that setting the extreme value to 0 corrected the sum. Now only 5 datapoints are invalid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47700664-97c4-4f63-8f6e-45735181a833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cropland</th>\n",
       "      <th>forest_deciduous_broad</th>\n",
       "      <th>forest_evergreen_broad</th>\n",
       "      <th>forest_evergreen_needle</th>\n",
       "      <th>forest_unknown</th>\n",
       "      <th>herbaceous_vegetation</th>\n",
       "      <th>shrubland</th>\n",
       "      <th>sprarse_vegetation</th>\n",
       "      <th>urban</th>\n",
       "      <th>water</th>\n",
       "      <th>wetland</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14704</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17444</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20679</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cropland  forest_deciduous_broad  forest_evergreen_broad  \\\n",
       "8031        NaN                     NaN                     NaN   \n",
       "10398       NaN                     NaN                     NaN   \n",
       "14704       NaN                     NaN                     NaN   \n",
       "17444       NaN                     NaN                     NaN   \n",
       "20679       NaN                     NaN                     NaN   \n",
       "\n",
       "       forest_evergreen_needle  forest_unknown  herbaceous_vegetation  \\\n",
       "8031                       NaN             NaN                    NaN   \n",
       "10398                      NaN             NaN                    NaN   \n",
       "14704                      NaN             NaN                    NaN   \n",
       "17444                      NaN             NaN                    NaN   \n",
       "20679                      NaN             NaN                    NaN   \n",
       "\n",
       "       shrubland  sprarse_vegetation  urban  water  wetland  \n",
       "8031         NaN                 NaN    NaN    NaN      NaN  \n",
       "10398        NaN                 NaN    NaN    NaN      NaN  \n",
       "14704        NaN                 NaN    NaN    NaN      NaN  \n",
       "17444        NaN                 NaN    NaN    NaN      NaN  \n",
       "20679        NaN                 NaN    NaN    NaN      NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the rows that still have an invalid sum\n",
    "df_invalid_sum = df.loc[invalid_sum_mask, veg_columns]\n",
    "\n",
    "df_invalid_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dcf390-9e42-4f9a-8c0f-c5e3c7600b6b",
   "metadata": {},
   "source": [
    "It can be seen that the 5 rows with invalid sums have NaN entries and can be dropped. However, prior to dropping the NaN rows, it is better to first go through all the data as dropping NaN rows early in the data processing, may drop useful data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bee0c8-c068-4c0d-8119-7ee4869e9b2c",
   "metadata": {},
   "source": [
    "From the information of the dataset, the weather data comes from multiple sources and may have inconsistent units. Therefore, the weather data specifically will be checked to ensure consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ebb3a30-f04a-4414-8762-0de5b6253b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_temp</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>yearly_avg_temp</th>\n",
       "      <th>max_max_temp</th>\n",
       "      <th>anom_max_temp</th>\n",
       "      <th>anom_avg_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.128294</td>\n",
       "      <td>158.859675</td>\n",
       "      <td>14.999730</td>\n",
       "      <td>59.230929</td>\n",
       "      <td>2.044202</td>\n",
       "      <td>1.941795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.435240</td>\n",
       "      <td>135.801507</td>\n",
       "      <td>0.083652</td>\n",
       "      <td>7.983432</td>\n",
       "      <td>3.026061</td>\n",
       "      <td>2.559182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.171763</td>\n",
       "      <td>-4.109107</td>\n",
       "      <td>14.597322</td>\n",
       "      <td>34.109174</td>\n",
       "      <td>-7.159943</td>\n",
       "      <td>-9.482144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.911636</td>\n",
       "      <td>7.687609</td>\n",
       "      <td>14.963919</td>\n",
       "      <td>53.440945</td>\n",
       "      <td>-0.098090</td>\n",
       "      <td>0.202694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.785950</td>\n",
       "      <td>276.348625</td>\n",
       "      <td>14.999554</td>\n",
       "      <td>58.614709</td>\n",
       "      <td>1.768574</td>\n",
       "      <td>1.928117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.254815</td>\n",
       "      <td>280.721741</td>\n",
       "      <td>15.034747</td>\n",
       "      <td>64.858667</td>\n",
       "      <td>3.918903</td>\n",
       "      <td>3.628255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32.431244</td>\n",
       "      <td>292.551632</td>\n",
       "      <td>15.369208</td>\n",
       "      <td>90.376239</td>\n",
       "      <td>16.340687</td>\n",
       "      <td>13.051181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           max_temp      avg_temp  yearly_avg_temp  max_max_temp  \\\n",
       "count  22035.000000  22035.000000     22035.000000  22035.000000   \n",
       "mean      15.128294    158.859675        14.999730     59.230929   \n",
       "std        4.435240    135.801507         0.083652      7.983432   \n",
       "min        1.171763     -4.109107        14.597322     34.109174   \n",
       "25%       11.911636      7.687609        14.963919     53.440945   \n",
       "50%       14.785950    276.348625        14.999554     58.614709   \n",
       "75%       18.254815    280.721741        15.034747     64.858667   \n",
       "max       32.431244    292.551632        15.369208     90.376239   \n",
       "\n",
       "       anom_max_temp  anom_avg_temp  \n",
       "count   22035.000000   22035.000000  \n",
       "mean        2.044202       1.941795  \n",
       "std         3.026061       2.559182  \n",
       "min        -7.159943      -9.482144  \n",
       "25%        -0.098090       0.202694  \n",
       "50%         1.768574       1.928117  \n",
       "75%         3.918903       3.628255  \n",
       "max        16.340687      13.051181  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking temperature fields to ensure consistency\n",
    "df[['max_temp', 'avg_temp', 'yearly_avg_temp', 'max_max_temp','anom_max_temp', 'anom_avg_temp']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab16bb7-c0cd-4d33-93d4-fdeb8365359f",
   "metadata": {},
   "source": [
    "From the above description, it can be seen that max_temp and yearly_avg_temp are in degrees celsius however, avg_temp has a mixture of units. The maximum value is 292.55 - which is impossible should it be in celsius or fahrenheit, therefore it must be in Kelvin. However, it was also noted that the minimum is -4.1 which is standard for celsius.\n",
    "\n",
    "From this description it can be seen that avg_temp has a mixture of data in Celsius and data in Kelvin.\n",
    "\n",
    "Furthermore, it can be seen that max_max_temp falls within a standard fahrenheit range. Therefore, it is undoubtadely in Fahrenheit and can be converted using a simple formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98fdeb04-c4e6-4ecd-be46-650511ebad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the max_temp values are true and therefore, it can be assumed that any temperature over 35 is definitely in Kelvin\n",
    "kelvin_mask = df['avg_temp'] > 35\n",
    "# Selecting the datapoints that are captured by the mask and converting them to degrees celsius\n",
    "df.loc[kelvin_mask, 'avg_temp'] = df.loc[kelvin_mask, 'avg_temp'] - 273.15\n",
    "\n",
    "# Converting max_max_temp into degrees celsius\n",
    "df['max_max_temp'] = (df['max_max_temp'] - 32) / 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73e02e47-a75a-46ae-aef1-9133d43a9db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_temp</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>yearly_avg_temp</th>\n",
       "      <th>max_max_temp</th>\n",
       "      <th>anom_max_temp</th>\n",
       "      <th>anom_avg_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.128294</td>\n",
       "      <td>7.316278</td>\n",
       "      <td>14.999730</td>\n",
       "      <td>15.128294</td>\n",
       "      <td>2.044202</td>\n",
       "      <td>1.941795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.435240</td>\n",
       "      <td>3.285425</td>\n",
       "      <td>0.083652</td>\n",
       "      <td>4.435240</td>\n",
       "      <td>3.026061</td>\n",
       "      <td>2.559182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.171763</td>\n",
       "      <td>-4.109107</td>\n",
       "      <td>14.597322</td>\n",
       "      <td>1.171763</td>\n",
       "      <td>-7.159943</td>\n",
       "      <td>-9.482144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.911636</td>\n",
       "      <td>5.025002</td>\n",
       "      <td>14.963919</td>\n",
       "      <td>11.911636</td>\n",
       "      <td>-0.098090</td>\n",
       "      <td>0.202694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.785950</td>\n",
       "      <td>7.156210</td>\n",
       "      <td>14.999554</td>\n",
       "      <td>14.785950</td>\n",
       "      <td>1.768574</td>\n",
       "      <td>1.928117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.254815</td>\n",
       "      <td>9.465587</td>\n",
       "      <td>15.034747</td>\n",
       "      <td>18.254815</td>\n",
       "      <td>3.918903</td>\n",
       "      <td>3.628255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32.431244</td>\n",
       "      <td>19.401632</td>\n",
       "      <td>15.369208</td>\n",
       "      <td>32.431244</td>\n",
       "      <td>16.340687</td>\n",
       "      <td>13.051181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           max_temp      avg_temp  yearly_avg_temp  max_max_temp  \\\n",
       "count  22035.000000  22035.000000     22035.000000  22035.000000   \n",
       "mean      15.128294      7.316278        14.999730     15.128294   \n",
       "std        4.435240      3.285425         0.083652      4.435240   \n",
       "min        1.171763     -4.109107        14.597322      1.171763   \n",
       "25%       11.911636      5.025002        14.963919     11.911636   \n",
       "50%       14.785950      7.156210        14.999554     14.785950   \n",
       "75%       18.254815      9.465587        15.034747     18.254815   \n",
       "max       32.431244     19.401632        15.369208     32.431244   \n",
       "\n",
       "       anom_max_temp  anom_avg_temp  \n",
       "count   22035.000000   22035.000000  \n",
       "mean        2.044202       1.941795  \n",
       "std         3.026061       2.559182  \n",
       "min        -7.159943      -9.482144  \n",
       "25%        -0.098090       0.202694  \n",
       "50%         1.768574       1.928117  \n",
       "75%         3.918903       3.628255  \n",
       "max        16.340687      13.051181  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rechecking to ensure consistency\n",
    "df[['max_temp', 'avg_temp', 'yearly_avg_temp', 'max_max_temp','anom_max_temp', 'anom_avg_temp']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f35b9-a2c3-4049-95ef-e4edd32f323c",
   "metadata": {},
   "source": [
    "It is now evident that the temperature fields are all in the same units. Moreover, max_max_temp has the same data as max_temp and can therefore be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da579fd4-7213-48f5-a952-2e0e4bf9b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['max_max_temp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5f9a7e0-8fed-4196-878d-a7bb7b4b5d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_wind_vel</th>\n",
       "      <th>anom_max_wind_vel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.728723</td>\n",
       "      <td>2.202667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.483441</td>\n",
       "      <td>3.320765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.978202</td>\n",
       "      <td>-7.363498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.858555</td>\n",
       "      <td>-0.172485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.250791</td>\n",
       "      <td>1.964479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.180290</td>\n",
       "      <td>4.269049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.703424</td>\n",
       "      <td>22.360945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       max_wind_vel  anom_max_wind_vel\n",
       "count  22035.000000       22035.000000\n",
       "mean       5.728723           2.202667\n",
       "std        2.483441           3.320765\n",
       "min        0.978202          -7.363498\n",
       "25%        3.858555          -0.172485\n",
       "50%        5.250791           1.964479\n",
       "75%        7.180290           4.269049\n",
       "max       19.703424          22.360945"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking wind speed fields to ensure consistency\n",
    "df[['max_wind_vel', 'anom_max_wind_vel']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ba334-5e18-40c4-b2e1-a920678e01a6",
   "metadata": {},
   "source": [
    "It can be seen that the wind speed variations are of the same magnitude and are therefore, consistent in units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0df00b69-1760-4578-aec2-2287bdbf78d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_prec</th>\n",
       "      <th>anom_sum_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.662872</td>\n",
       "      <td>0.040211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.230198</td>\n",
       "      <td>1.042084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-3.103708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.710898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.154361</td>\n",
       "      <td>-0.090009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.854040</td>\n",
       "      <td>0.691713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.440075</td>\n",
       "      <td>4.699601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sum_prec  anom_sum_prec\n",
       "count  22035.000000   22035.000000\n",
       "mean       1.662872       0.040211\n",
       "std        3.230198       1.042084\n",
       "min       -0.000007      -3.103708\n",
       "25%        0.000000      -0.710898\n",
       "50%        0.154361      -0.090009\n",
       "75%        1.854040       0.691713\n",
       "max       40.440075       4.699601"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking precipitation amounts to ensure consistency\n",
    "df[['sum_prec', 'anom_sum_prec']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4462017-9152-4a49-aa80-624ab53b749c",
   "metadata": {},
   "source": [
    "There is a wide range in the precipitation data, from no rainfall to a maximum of 40.44. Moreover, 75% of the data is within 1.85, indicating that this large 40.44 could be classed as an outlier, indicating an extreme case. Realistically 40.44 mm of rainfall in a day is a lot but plausible with extreme rainfall. Therefore, no adjustments need to be done for the precipitation data.\n",
    "\n",
    "Moreover, it can be seen that the anom_{features} have non-zero means and non-one standard deviations. These indicating that the standardisation done prior to data loading was done badly or not even standardised. Only anom_sum_prec appears to be standardised well. Therefore, the rest should be restandardised or dropped. First let's inspect all the anom_{features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "320f882b-6af7-4a9e-b047-48fc8eff9953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anom_max_temp</th>\n",
       "      <th>anom_max_wind_vel</th>\n",
       "      <th>anom_avg_temp</th>\n",
       "      <th>anom_avg_rel_hum</th>\n",
       "      <th>anom_avg_soil</th>\n",
       "      <th>anom_sum_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.044202</td>\n",
       "      <td>2.202667</td>\n",
       "      <td>1.941795</td>\n",
       "      <td>2.231864</td>\n",
       "      <td>0.458071</td>\n",
       "      <td>0.040211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.026061</td>\n",
       "      <td>3.320765</td>\n",
       "      <td>2.559182</td>\n",
       "      <td>2.796936</td>\n",
       "      <td>1.651015</td>\n",
       "      <td>1.042084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.159943</td>\n",
       "      <td>-7.363498</td>\n",
       "      <td>-9.482144</td>\n",
       "      <td>-9.155835</td>\n",
       "      <td>-6.903322</td>\n",
       "      <td>-3.103708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.098090</td>\n",
       "      <td>-0.172485</td>\n",
       "      <td>0.202694</td>\n",
       "      <td>0.293640</td>\n",
       "      <td>-0.727537</td>\n",
       "      <td>-0.710898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.768574</td>\n",
       "      <td>1.964479</td>\n",
       "      <td>1.928117</td>\n",
       "      <td>2.066875</td>\n",
       "      <td>0.439721</td>\n",
       "      <td>-0.090009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.918903</td>\n",
       "      <td>4.269049</td>\n",
       "      <td>3.628255</td>\n",
       "      <td>4.100976</td>\n",
       "      <td>1.647857</td>\n",
       "      <td>0.691713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16.340687</td>\n",
       "      <td>22.360945</td>\n",
       "      <td>13.051181</td>\n",
       "      <td>15.005052</td>\n",
       "      <td>8.484861</td>\n",
       "      <td>4.699601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anom_max_temp  anom_max_wind_vel  anom_avg_temp  anom_avg_rel_hum  \\\n",
       "count   22035.000000       22035.000000   22035.000000      22035.000000   \n",
       "mean        2.044202           2.202667       1.941795          2.231864   \n",
       "std         3.026061           3.320765       2.559182          2.796936   \n",
       "min        -7.159943          -7.363498      -9.482144         -9.155835   \n",
       "25%        -0.098090          -0.172485       0.202694          0.293640   \n",
       "50%         1.768574           1.964479       1.928117          2.066875   \n",
       "75%         3.918903           4.269049       3.628255          4.100976   \n",
       "max        16.340687          22.360945      13.051181         15.005052   \n",
       "\n",
       "       anom_avg_soil  anom_sum_prec  \n",
       "count   22035.000000   22035.000000  \n",
       "mean        0.458071       0.040211  \n",
       "std         1.651015       1.042084  \n",
       "min        -6.903322      -3.103708  \n",
       "25%        -0.727537      -0.710898  \n",
       "50%         0.439721      -0.090009  \n",
       "75%         1.647857       0.691713  \n",
       "max         8.484861       4.699601  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selectin anom_{features}\n",
    "anom_cols = [col for col in df.columns if col.startswith('anom_')]\n",
    "# Describing the anom_{features}\n",
    "df[anom_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b22add9f-9fcc-42f4-8a4d-61dd2fa1c9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anom_max_temp</th>\n",
       "      <th>anom_max_wind_vel</th>\n",
       "      <th>anom_avg_temp</th>\n",
       "      <th>anom_avg_rel_hum</th>\n",
       "      <th>anom_avg_soil</th>\n",
       "      <th>anom_sum_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.203500e+04</td>\n",
       "      <td>2.203500e+04</td>\n",
       "      <td>2.203500e+04</td>\n",
       "      <td>2.203500e+04</td>\n",
       "      <td>2.203500e+04</td>\n",
       "      <td>2.203500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.579688e-17</td>\n",
       "      <td>1.305967e-17</td>\n",
       "      <td>8.383985e-18</td>\n",
       "      <td>2.579688e-17</td>\n",
       "      <td>-3.611563e-17</td>\n",
       "      <td>2.837656e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.041626e+00</td>\n",
       "      <td>-2.880711e+00</td>\n",
       "      <td>-4.463903e+00</td>\n",
       "      <td>-4.071490e+00</td>\n",
       "      <td>-4.458708e+00</td>\n",
       "      <td>-3.016953e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.079473e-01</td>\n",
       "      <td>-7.152424e-01</td>\n",
       "      <td>-6.795536e-01</td>\n",
       "      <td>-6.929810e-01</td>\n",
       "      <td>-7.181091e-01</td>\n",
       "      <td>-7.207753e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-9.108472e-02</td>\n",
       "      <td>-7.172687e-02</td>\n",
       "      <td>-5.344783e-03</td>\n",
       "      <td>-5.898941e-02</td>\n",
       "      <td>-1.111437e-02</td>\n",
       "      <td>-1.249613e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.195189e-01</td>\n",
       "      <td>6.222608e-01</td>\n",
       "      <td>6.589839e-01</td>\n",
       "      <td>6.682710e-01</td>\n",
       "      <td>7.206386e-01</td>\n",
       "      <td>6.251922e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.724454e+00</td>\n",
       "      <td>6.070371e+00</td>\n",
       "      <td>4.340991e+00</td>\n",
       "      <td>4.566849e+00</td>\n",
       "      <td>4.861731e+00</td>\n",
       "      <td>4.471224e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anom_max_temp  anom_max_wind_vel  anom_avg_temp  anom_avg_rel_hum  \\\n",
       "count   2.203500e+04       2.203500e+04   2.203500e+04      2.203500e+04   \n",
       "mean    2.579688e-17       1.305967e-17   8.383985e-18      2.579688e-17   \n",
       "std     1.000000e+00       1.000000e+00   1.000000e+00      1.000000e+00   \n",
       "min    -3.041626e+00      -2.880711e+00  -4.463903e+00     -4.071490e+00   \n",
       "25%    -7.079473e-01      -7.152424e-01  -6.795536e-01     -6.929810e-01   \n",
       "50%    -9.108472e-02      -7.172687e-02  -5.344783e-03     -5.898941e-02   \n",
       "75%     6.195189e-01       6.222608e-01   6.589839e-01      6.682710e-01   \n",
       "max     4.724454e+00       6.070371e+00   4.340991e+00      4.566849e+00   \n",
       "\n",
       "       anom_avg_soil  anom_sum_prec  \n",
       "count   2.203500e+04   2.203500e+04  \n",
       "mean   -3.611563e-17   2.837656e-17  \n",
       "std     1.000000e+00   1.000000e+00  \n",
       "min    -4.458708e+00  -3.016953e+00  \n",
       "25%    -7.181091e-01  -7.207753e-01  \n",
       "50%    -1.111437e-02  -1.249613e-01  \n",
       "75%     7.206386e-01   6.251922e-01  \n",
       "max     4.861731e+00   4.471224e+00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing column-wise standardisation on all the anom_{features}\n",
    "for col in anom_cols:\n",
    "    mean = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    df[col] = (df[col] - mean) / std\n",
    "df[anom_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e1d6c5-f792-49a5-8974-980ced7c01ca",
   "metadata": {},
   "source": [
    "anom_{features} are now properly standardised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8aa7526a-14bb-429e-84fd-37b0533d33af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22035 entries, 0 to 22034\n",
      "Data columns (total 39 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   distance_fire_stations   22030 non-null  float64\n",
      " 1   distance_rivers          22030 non-null  float64\n",
      " 2   distance_roads           22030 non-null  float64\n",
      " 3   distance_powerlines      22030 non-null  float64\n",
      " 4   cropland                 22030 non-null  float64\n",
      " 5   forest_deciduous_broad   22030 non-null  float64\n",
      " 6   forest_evergreen_broad   22030 non-null  float64\n",
      " 7   forest_evergreen_needle  22030 non-null  float64\n",
      " 8   forest_unknown           22030 non-null  float64\n",
      " 9   herbaceous_vegetation    22030 non-null  float64\n",
      " 10  shrubland                22030 non-null  float64\n",
      " 11  sprarse_vegetation       22030 non-null  float64\n",
      " 12  urban                    22030 non-null  float64\n",
      " 13  water                    22030 non-null  float64\n",
      " 14  wetland                  22030 non-null  float64\n",
      " 15  aspect                   22035 non-null  float64\n",
      " 16  elevation                22035 non-null  float64\n",
      " 17  pop_dens                 22035 non-null  float64\n",
      " 18  slope                    22035 non-null  float64\n",
      " 19  anom_max_temp            22035 non-null  float64\n",
      " 20  anom_max_wind_vel        22035 non-null  float64\n",
      " 21  anom_avg_temp            22035 non-null  float64\n",
      " 22  anom_avg_rel_hum         22035 non-null  float64\n",
      " 23  anom_avg_soil            22035 non-null  float64\n",
      " 24  anom_sum_prec            22035 non-null  float64\n",
      " 25  max_temp                 22035 non-null  float64\n",
      " 26  max_wind_vel             22035 non-null  float64\n",
      " 27  avg_temp                 22035 non-null  float64\n",
      " 28  avg_wind_angle           22035 non-null  float64\n",
      " 29  avg_rel_hum              22035 non-null  float64\n",
      " 30  avg_soil                 22035 non-null  float64\n",
      " 31  sum_prec                 22035 non-null  float64\n",
      " 32  forest                   22035 non-null  float64\n",
      " 33  vegetation_class         22003 non-null  object \n",
      " 34  yearly_avg_temp          22035 non-null  float64\n",
      " 35  ignition                 22035 non-null  int64  \n",
      " 36  Month                    22035 non-null  int32  \n",
      " 37  DayofYear                22035 non-null  int32  \n",
      " 38  Year                     22035 non-null  int32  \n",
      "dtypes: float64(34), int32(3), int64(1), object(1)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9364af-56da-4410-8533-1dc0d53485a2",
   "metadata": {},
   "source": [
    "Now only 32 rows contain NaN data and can therefore be dropped as their influence can be assumed negligible since 32 << 22035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "943149bf-0d11-434f-b4a4-9ebc6b41a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the rows with NaN entries\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baeeb81-8527-4091-81a7-4d33396770de",
   "metadata": {},
   "source": [
    "From the orginal description of the dataframe, it was noted that the minimum distance values are 0. Although this is possible, it is highly unlikely. For example, how likely is it that an ignition of a wildfire started at a fire station?\n",
    "\n",
    "The number should be checked and the entries with 0 distance should be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7aad21e-e11b-4852-a40a-300abeaf2e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance_roads            3103\n",
       "distance_fire_stations       3\n",
       "distance_powerlines        157\n",
       "distance_rivers           1337\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[['distance_roads', 'distance_fire_stations', 'distance_powerlines', 'distance_rivers']] == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c91a2-0368-4cb2-aa76-e34903794330",
   "metadata": {},
   "source": [
    "It is likely that an ignition point occured on roads, powerlines and rivers, so these could be true. Although it is very unlikely that an ignition occured at fire station, only 3 ignitions occured at a fire station. Therefore, it is highly rare but possible. \n",
    "\n",
    "As a result, nothing will be done to these datapoints as they are not unreasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae967bf-d3f0-4cdc-89ff-86edaa215014",
   "metadata": {},
   "source": [
    "All that is left is to process the vegetation_class as it is of type object. It can be assumed that there may be errors in the string entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33b63851-9a4c-4f10-b5d9-f79c4e7ede20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['forest', 'wetland', 'herbaceous_vegetation', 'Forestt',\n",
       "       'shrubland', 'water', 'urban', '$herb$aceous_vegetation'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the unique classes in vegetation_class\n",
    "df['vegetation_class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d16d6e-45f2-49af-aacf-3e3e373b9705",
   "metadata": {},
   "source": [
    "As expected, there are spelling mistakes these must be arranged. Since, there are only a few these can be arranged simply through a mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2eab5209-5745-4159-be09-ba0f5e91314d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['forest', 'wetland', 'herbaceous_vegetation', 'shrubland', 'water',\n",
       "       'urban'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a mapping dictionary\n",
    "veg_mapping = {\n",
    "    'Forestt': 'forest',\n",
    "    '$herb$aceous_vegetation': 'herbaceous_vegetation',\n",
    "    np.nan: 'unknown'\n",
    "}\n",
    "\n",
    "# Applying the mapping\n",
    "df['vegetation_class'] = df['vegetation_class'].replace(veg_mapping)\n",
    "\n",
    "# Checking the uniqueness again\n",
    "df['vegetation_class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14889d4-9f5e-4cad-b82c-69097b242a35",
   "metadata": {},
   "source": [
    "To be able to train a classification model, the objects must be one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f3a26b8-f3d2-417d-8fdf-6be6279df5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_fire_stations</th>\n",
       "      <th>distance_rivers</th>\n",
       "      <th>distance_roads</th>\n",
       "      <th>distance_powerlines</th>\n",
       "      <th>cropland</th>\n",
       "      <th>forest_deciduous_broad</th>\n",
       "      <th>forest_evergreen_broad</th>\n",
       "      <th>forest_evergreen_needle</th>\n",
       "      <th>forest_unknown</th>\n",
       "      <th>herbaceous_vegetation</th>\n",
       "      <th>...</th>\n",
       "      <th>yearly_avg_temp</th>\n",
       "      <th>ignition</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofYear</th>\n",
       "      <th>Year</th>\n",
       "      <th>vegetation_class_herbaceous_vegetation</th>\n",
       "      <th>vegetation_class_shrubland</th>\n",
       "      <th>vegetation_class_urban</th>\n",
       "      <th>vegetation_class_water</th>\n",
       "      <th>vegetation_class_wetland</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13287.682266</td>\n",
       "      <td>7211.102551</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>30196.233209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.994683</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>323</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8721.381771</td>\n",
       "      <td>2358.495283</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>13768.169813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>15.053698</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10796.411441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015.564437</td>\n",
       "      <td>6254.998002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.001883</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8253.787010</td>\n",
       "      <td>559.016994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37350.535471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>14.850611</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>315</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9905.806378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1903.943276</td>\n",
       "      <td>6427.480066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>15.002587</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22030</th>\n",
       "      <td>12260.199835</td>\n",
       "      <td>1820.027472</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>39374.007924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.994649</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22031</th>\n",
       "      <td>8933.784193</td>\n",
       "      <td>3889.087297</td>\n",
       "      <td>790.569415</td>\n",
       "      <td>40380.998006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.045942</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>295</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22032</th>\n",
       "      <td>56560.255480</td>\n",
       "      <td>1030.776406</td>\n",
       "      <td>6388.466170</td>\n",
       "      <td>23538.532240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.982935</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>154</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22033</th>\n",
       "      <td>94191.294715</td>\n",
       "      <td>16839.314119</td>\n",
       "      <td>14637.281168</td>\n",
       "      <td>83236.485390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.897028</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>157</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22034</th>\n",
       "      <td>41926.274578</td>\n",
       "      <td>707.106781</td>\n",
       "      <td>3092.329219</td>\n",
       "      <td>39957.790229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.002066</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22003 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       distance_fire_stations  distance_rivers  distance_roads  \\\n",
       "0                13287.682266      7211.102551     1250.000000   \n",
       "1                 8721.381771      2358.495283      250.000000   \n",
       "2                10796.411441         0.000000     2015.564437   \n",
       "3                 8253.787010       559.016994        0.000000   \n",
       "4                 9905.806378         0.000000     1903.943276   \n",
       "...                       ...              ...             ...   \n",
       "22030            12260.199835      1820.027472      500.000000   \n",
       "22031             8933.784193      3889.087297      790.569415   \n",
       "22032            56560.255480      1030.776406     6388.466170   \n",
       "22033            94191.294715     16839.314119    14637.281168   \n",
       "22034            41926.274578       707.106781     3092.329219   \n",
       "\n",
       "       distance_powerlines  cropland  forest_deciduous_broad  \\\n",
       "0             30196.233209       0.0                     0.0   \n",
       "1             13768.169813       0.0                     0.0   \n",
       "2              6254.998002       0.0                     0.0   \n",
       "3             37350.535471       0.0                     0.0   \n",
       "4              6427.480066       0.0                     0.0   \n",
       "...                    ...       ...                     ...   \n",
       "22030         39374.007924       0.0                     0.0   \n",
       "22031         40380.998006       0.0                     0.0   \n",
       "22032         23538.532240       0.0                     0.0   \n",
       "22033         83236.485390       0.0                     0.0   \n",
       "22034         39957.790229       0.0                     0.0   \n",
       "\n",
       "       forest_evergreen_broad  forest_evergreen_needle  forest_unknown  \\\n",
       "0                    1.000000                      0.0        0.000000   \n",
       "1                    0.416667                      0.0        0.416667   \n",
       "2                    0.666667                      0.0        0.333333   \n",
       "3                    0.000000                      0.0        0.000000   \n",
       "4                    0.750000                      0.0        0.166667   \n",
       "...                       ...                      ...             ...   \n",
       "22030                0.000000                      0.0        0.000000   \n",
       "22031                1.000000                      0.0        0.000000   \n",
       "22032                1.000000                      0.0        0.000000   \n",
       "22033                0.000000                      0.0        0.000000   \n",
       "22034                0.000000                      0.0        0.000000   \n",
       "\n",
       "       herbaceous_vegetation  ...  yearly_avg_temp  ignition  Month  \\\n",
       "0                   0.000000  ...        14.994683         1     11   \n",
       "1                   0.166667  ...        15.053698         1      2   \n",
       "2                   0.000000  ...        15.001883         1      2   \n",
       "3                   0.166667  ...        14.850611         1     11   \n",
       "4                   0.083333  ...        15.002587         1      3   \n",
       "...                      ...  ...              ...       ...    ...   \n",
       "22030               0.000000  ...        14.994649         0      5   \n",
       "22031               0.000000  ...        15.045942         0     10   \n",
       "22032               0.000000  ...        14.982935         0      6   \n",
       "22033               0.000000  ...        14.897028         0      6   \n",
       "22034               0.500000  ...        15.002066         0      1   \n",
       "\n",
       "       DayofYear  Year  vegetation_class_herbaceous_vegetation  \\\n",
       "0            323  2015                                       0   \n",
       "1             48  2003                                       0   \n",
       "2             57  2012                                       0   \n",
       "3            315  2004                                       0   \n",
       "4             78  2003                                       0   \n",
       "...          ...   ...                                     ...   \n",
       "22030        137  2013                                       0   \n",
       "22031        295  2017                                       0   \n",
       "22032        154  2019                                       0   \n",
       "22033        157  2007                                       0   \n",
       "22034         21  2016                                       1   \n",
       "\n",
       "       vegetation_class_shrubland  vegetation_class_urban  \\\n",
       "0                               0                       0   \n",
       "1                               0                       0   \n",
       "2                               0                       0   \n",
       "3                               0                       0   \n",
       "4                               0                       0   \n",
       "...                           ...                     ...   \n",
       "22030                           0                       0   \n",
       "22031                           0                       0   \n",
       "22032                           0                       0   \n",
       "22033                           0                       0   \n",
       "22034                           0                       0   \n",
       "\n",
       "       vegetation_class_water  vegetation_class_wetland  \n",
       "0                           0                         0  \n",
       "1                           0                         0  \n",
       "2                           0                         0  \n",
       "3                           0                         1  \n",
       "4                           0                         0  \n",
       "...                       ...                       ...  \n",
       "22030                       1                         0  \n",
       "22031                       0                         0  \n",
       "22032                       0                         0  \n",
       "22033                       1                         0  \n",
       "22034                       0                         0  \n",
       "\n",
       "[22003 rows x 43 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding using pandas\n",
    "df = pd.get_dummies(df, columns=['vegetation_class'], drop_first=True, dtype=int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c40a9-dcce-4ef9-b45b-671479c21d73",
   "metadata": {},
   "source": [
    "## Feature Selection and Splitting the Data into Train and Test Sets\n",
    "Prior to splitting the dataset into train and test sets, it is valuable to see the distribution of classes that is, the balance between the number of ignition and non-ignition points. It is important that the train and test sets are statistically representative of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e09b630-4035-4f79-b555-72e34f59e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the distribution of non-ignition and ignition points ignition\n",
      "0    84.911148\n",
      "1    15.088852\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Selecting features by dropping the ignition column\n",
    "X = df.drop(columns='ignition')\n",
    "# Selecting ignition as the label\n",
    "y = df['ignition']\n",
    "\n",
    "print(\"This is the distribution of non-ignition and ignition points\", y.value_counts() * 100 / y.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2ea7a-e31d-4467-bc25-d215b4a4d203",
   "metadata": {},
   "source": [
    "There is an imbalance of ignition and non-ignition points therefore, it is required that the test and train sets have that same representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb833bac-819c-4983-8d05-a946230a2cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the distribution of non-ignition and ignition points in train set ignition\n",
      "0    84.910806\n",
      "1    15.089194\n",
      "Name: count, dtype: float64\n",
      "This is the distribution of non-ignition and ignition points in test set ignition\n",
      "0    84.91252\n",
      "1    15.08748\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn's dataset splitter\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"This is the distribution of non-ignition and ignition points in train set\", y_train.value_counts() * 100 / y_train.count())\n",
    "print(\"This is the distribution of non-ignition and ignition points in test set\", y_test.value_counts() * 100 / y_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbff87e7-19e7-48e7-aafb-e908428b143d",
   "metadata": {},
   "source": [
    "Using the stratify function, sklearn preserved the data split. The float64 data must now be standardised. Standardisation is done using a scaler fitted to the training data only because in reality the model works on un-seen data which the scaler will not be refit on. The model needs to be able to handle data standardised using its training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9df8ab55-3935-4c16-8c4e-eadeb6b9b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selecting the float columns and non-float columns\n",
    "float_cols = X_train.select_dtypes(include='float64').columns\n",
    "non_float_cols = X_train.columns.difference(float_cols)\n",
    "\n",
    "# Fitting a scaler on the training data only but then applying it to both the train and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_float = scaler.fit_transform(X_train[float_cols])\n",
    "X_test_scaled_float = scaler.transform(X_test[float_cols])\n",
    "\n",
    "# Converting back into a DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled_float, columns=float_cols, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled_float, columns=float_cols, index=X_test.index)\n",
    "\n",
    "# Concatenating to include the one-hot encoded entries\n",
    "X_train_final = pd.concat([X_train_scaled, X_train[non_float_cols]], axis=1)\n",
    "X_test_final = pd.concat([X_test_scaled, X_test[non_float_cols]], axis=1)\n",
    "\n",
    "# Extracting the values from the DataFrame\n",
    "X_test_values = X_test_final.values\n",
    "X_train_values = X_train_final.values\n",
    "\n",
    "y_test_values = y_test.values\n",
    "y_train_values = y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3ce8e-8ecf-4834-a09d-f7779c99d4d6",
   "metadata": {},
   "source": [
    "## Algorithm Selection, Training and Evaluation\n",
    "\n",
    "From the above data distribution and the project objective, the overall task is **stratified binary classification**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f83ff-f27e-482c-9bfc-af749e816ebb",
   "metadata": {},
   "source": [
    "In terms of algorithm selection, possible candidates are:\n",
    "\n",
    "1. Logistic regression\n",
    "2. Support Vector Machines\n",
    "3. Random Forest\n",
    "4. Gradient Boosted Classification\n",
    "5. Neural Networks\n",
    "\n",
    "It is best practice to always start from the simplest algorithm, in this case logistic regression. Not only does starting from the simplest algorithm provide a solid baseline for comparison, but also avoid using too complex and costly algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d678d1ae-00b4-45b6-ad19-f96158bef1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.964     0.777     0.860      3737\n",
      "           1      0.400     0.837     0.541       664\n",
      "\n",
      "    accuracy                          0.786      4401\n",
      "   macro avg      0.682     0.807     0.701      4401\n",
      "weighted avg      0.879     0.786     0.812      4401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the required packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Defining the model\n",
    "LR_model = LogisticRegression( class_weight='balanced', random_state=42, max_iter = 5000)\n",
    "LR_model.fit(X_train_values, y_train_values)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = LR_model.predict(X_test_values)\n",
    "\n",
    "# Computing the performance metrics\n",
    "print(classification_report(y_test_values, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efa4ff8f-331c-4a4e-9a57-1101dffc4033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.966     0.771     0.857      3737\n",
      "           1      0.396     0.846     0.540       664\n",
      "\n",
      "    accuracy                          0.782      4401\n",
      "   macro avg      0.681     0.809     0.699      4401\n",
      "weighted avg      0.880     0.782     0.810      4401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing required packages\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Defining the model\n",
    "svm_model = LinearSVC(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Training the model\n",
    "svm_model.fit(X_train_values, y_train_values)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_sgd = svm_model.predict(X_test_values)\n",
    "\n",
    "print(classification_report(y_test_values, y_pred_sgd, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b3874d3-2350-4ed1-a333-f8fb16ee394a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.900     0.980     0.938      3737\n",
      "           1      0.775     0.384     0.514       664\n",
      "\n",
      "    accuracy                          0.890      4401\n",
      "   macro avg      0.837     0.682     0.726      4401\n",
      "weighted avg      0.881     0.890     0.874      4401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing required packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Defining the model\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "rf_model.fit(X_train_values, y_train_values)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_rf = rf_model.predict(X_test_values)\n",
    "\n",
    "print(classification_report(y_test_values, y_pred_rf, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dc35b0b-a66d-436c-b0bf-7e67e4df8861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.906     0.965     0.935      3737\n",
      "           1      0.691     0.434     0.533       664\n",
      "\n",
      "    accuracy                          0.885      4401\n",
      "   macro avg      0.798     0.700     0.734      4401\n",
      "weighted avg      0.873     0.885     0.874      4401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing required packages\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Defining the model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "gb_model.fit(X_train_values, y_train_values)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_gb = gb_model.predict(X_test_values)\n",
    "\n",
    "print(classification_report(y_test_values, y_pred_gb, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "909fec28-87b3-4e0b-a145-ee9666b61faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.857     0.991     0.919      3737\n",
      "           1      0.593     0.072     0.129       664\n",
      "\n",
      "    accuracy                          0.853      4401\n",
      "   macro avg      0.725     0.532     0.524      4401\n",
      "weighted avg      0.817     0.853     0.800      4401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Defining the model\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(32, 32),  \n",
    "    activation='relu',            \n",
    "    solver='adam',                 \n",
    "    max_iter=5000,                 \n",
    "    random_state=42,\n",
    "    learning_rate_init=1e-4\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "nn_model.fit(X_train_values, y_train_values)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_nn = nn_model.predict(X_test_values)\n",
    "\n",
    "print(classification_report(y_test_values, y_pred_nn, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de905d89-059c-4cd1-a013-93ef06cc280e",
   "metadata": {},
   "source": [
    "### Evaluating the models\n",
    "\n",
    "To evaluate the models, sklearn's classification report was used. The classification report gives detailed insight into the model's capability to predict both classes. Prior to comparing the models, it is important to understand what each scoring metric represents\n",
    "\n",
    "- **Precision**: Represents that ratio of true positives and the total number of predicted positives. In other words, of all the times the model predicted a class, how often was it correct\n",
    "- **Recall**: Represents the ratio of true positives and the total number of actual positives. In other words, of all the actual ignition events, how many were correctly identified.\n",
    "- **F1 score**: This is a balance between the precision and recall. It provides a measure when both false positives and false negatives are important\n",
    "\n",
    "Accuracy is avoided as it is not a reliable metric in this case due to the imbalance in classes. Ignition events are much rarer than non-ignition events. A model that predicts no igntion each time would still achieve high accuracy while failing to identify actual ignition points. This would give a false impression of the model quality.\n",
    "\n",
    "In the context of parametric insurance for wildfire cases, the primary goal is to correctly identify as many ignition points as possible. Missing an ignition (a false negative) could lead to serious consequences, that is not paying out a client when they should have been paid out, while over predicting (a false positive) would lead to paying out clients when not needed. Therefore, model evaluation is primarily focused on the precision and recall of the ignition cases. This meaning that we want high scores for precision and recall for the case the class is 1 (ignition) and would manifest itself in a high f1 score for class 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0202dde1-1933-440e-94c0-ae85694592bc",
   "metadata": {},
   "source": [
    "#### Comparison of the Tested Models\n",
    "\n",
    "As discussed above, 5 models algorithms were tested. Firstly, it is important to note that none of these algorithms were highly optimised as performance was not the main goal of this project.\n",
    "\n",
    "When comparing the unoptimised models, the logistic regression algorithm worked best with an f1 score of 0.541 followed closely by the SVM with an f1 score of 0.540 and gradient boosting algorithm with an f1 score of 0.533. The reason for the logistic regression algorithm being the highest performing could be due to it being the simplest and therefore requiring little to no tuning. On the other hand, more complex algorithms such as random forest, gradient boost and NNs are capable of much higher performance but require more attentative parameter tuning, therefore their lack of performance can be attributed to a lack of tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f5dd5-2bf6-496d-96d7-e74d0c74e808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
